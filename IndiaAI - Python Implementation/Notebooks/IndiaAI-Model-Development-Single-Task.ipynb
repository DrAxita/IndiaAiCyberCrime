{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791a2cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files converted to UTF-8 successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the files with latin1 encoding\n",
    "train_df = pd.read_csv('train.csv', encoding='latin1')\n",
    "test_df = pd.read_csv('test.csv', encoding='latin1')\n",
    "\n",
    "# Save them back in UTF-8 encoding\n",
    "train_df.to_csv('train_utf8.csv', index=False, encoding='utf-8')\n",
    "test_df.to_csv('test_utf8.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Files converted to UTF-8 successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e6577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_utf8.csv')\n",
    "test_df = pd.read_csv('test_utf8.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d9c775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93686 entries, 0 to 93685\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   category            93686 non-null  object\n",
      " 1   sub_category        87095 non-null  object\n",
      " 2   crimeaditionalinfo  93665 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "\n",
      "Missing Values in Training Data:\n",
      "category                 0\n",
      "sub_category          6591\n",
      "crimeaditionalinfo      21\n",
      "dtype: int64\n",
      "\n",
      "Unique values in 'category':\n",
      "['Online and Social Media Related Crime' 'Online Financial Fraud'\n",
      " 'Online Gambling  Betting' 'RapeGang Rape RGRSexually Abusive Content'\n",
      " 'Any Other Cyber Crime']\n",
      "\n",
      "Unique values in 'sub_category':\n",
      "['Cyber Bullying  Stalking  Sexting' 'Fraud CallVishing'\n",
      " 'Online Gambling  Betting' 'Online Job Fraud' 'UPI Related Frauds']\n",
      "\n",
      "Unique values in 'crimeaditionalinfo':\n",
      "['I had continue received random calls and abusive messages in my whatsapp Someone added my number in a unknown facebook group name with  Only Girls  and still getting calls from unknown numbers pls help me and sort out the issue  as soon as possible Thank you'\n",
      " 'The above fraudster is continuously messaging me and Asking me to pay him money or he will send fake  cropped nude photos of me to my other contacts through WhatsApp\\r\\n\\r\\nI am unaware how he has recieved my contacts list from my phone\\r\\n\\r\\nPlease help'\n",
      " 'He is acting like a police and demanding for money by adding sections in the text messages \\r\\nI request you to take an immediate action on him Frequently he is harassing with these messages For reference please find attached files'\n",
      " 'In apna Job I have applied for job interview for telecalling and the resource management wrote that twelve hundred will be charged for security amount of laptop and work from home when I have given interview on the given address next day they charged twelve hundred and six hundred more money in the name of insurance after that they have referred me to the job calling there is no work of laptop neither a work from home kindly please take action against it as soon as possible and if possible please help me to recover my financial loss'\n",
      " 'I received a call from lady stating that she will send new phone of vivo and I received that parcel through post on  th February to Kurnool head post office  where I have not received any mobile']\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the training data\n",
    "print(\"Training Data Info:\")\n",
    "print(train_df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Training Data:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Display some unique values in the columns\n",
    "for column in train_df.columns:\n",
    "    print(f\"\\nUnique values in '{column}':\")\n",
    "    print(train_df[column].unique()[:5])  # Show only first 5 unique values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ac82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Missing Values:\n",
      "category              0\n",
      "sub_category          0\n",
      "crimeaditionalinfo    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing 'crimeaditionalinfo'\n",
    "train_df = train_df.dropna(subset=['crimeaditionalinfo'])\n",
    "\n",
    "# Fill missing 'sub_category' with a placeholder (e.g., 'Unknown')\n",
    "train_df['sub_category'] = train_df['sub_category'].fillna('Unknown')\n",
    "\n",
    "# Verify the changes\n",
    "print(\"Updated Missing Values:\")\n",
    "print(train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95bdc2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daee5320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Processed Text:\n",
      "                                  crimeaditionalinfo  \\\n",
      "0  I had continue received random calls and abusi...   \n",
      "1  The above fraudster is continuously messaging ...   \n",
      "2  He is acting like a police and demanding for m...   \n",
      "3  In apna Job I have applied for job interview f...   \n",
      "4  I received a call from lady stating that she w...   \n",
      "\n",
      "                                      processed_text  \n",
      "0  continue received random call abusive message ...  \n",
      "1  fraudster continuously messaging asking pay mo...  \n",
      "2  acting like police demanding money adding sect...  \n",
      "3  apna job applied job interview telecalling res...  \n",
      "4  received call lady stating send new phone vivo...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize stop words and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Removing punctuation and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the 'crimeaditionalinfo' column\n",
    "train_df['processed_text'] = train_df['crimeaditionalinfo'].apply(preprocess_text)\n",
    "\n",
    "# Display the processed text\n",
    "print(\"Sample Processed Text:\")\n",
    "print(train_df[['crimeaditionalinfo', 'processed_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa9119b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix Shape: (93665, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limit to top 5000 features for efficiency\n",
    "\n",
    "# Fit and transform the 'processed_text' column\n",
    "X = tfidf_vectorizer.fit_transform(train_df['processed_text'])\n",
    "\n",
    "# Display the shape of the resulting feature matrix\n",
    "print(\"Feature Matrix Shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "209f60ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Category Values: ['Online and Social Media Related Crime' 'Online Financial Fraud'\n",
      " 'Online Gambling  Betting' 'RapeGang Rape RGRSexually Abusive Content'\n",
      " 'Any Other Cyber Crime' 'Cyber Attack/ Dependent Crimes'\n",
      " 'Cryptocurrency Crime' 'Sexually Explicit Act'\n",
      " 'Sexually Obscene material'\n",
      " 'Hacking  Damage to computercomputer system etc' 'Cyber Terrorism'\n",
      " 'Child Pornography CPChild Sexual Abuse Material CSAM'\n",
      " 'Online Cyber Trafficking' 'Ransomware']\n",
      "Updated Subcategory Values: ['Cyber Bullying  Stalking  Sexting' 'Fraud CallVishing'\n",
      " 'Online Gambling  Betting' 'Online Job Fraud' 'UPI Related Frauds'\n",
      " 'Internet Banking Related Fraud' 'Unknown' 'Other'\n",
      " 'Profile Hacking Identity Theft' 'DebitCredit Card FraudSim Swap Fraud'\n",
      " 'EWallet Related Fraud' 'Data Breach/Theft' 'Cheating by Impersonation'\n",
      " 'Denial of Service (DoS)/Distributed Denial of Service (DDOS) attacks'\n",
      " 'FakeImpersonating Profile' 'Cryptocurrency Fraud' 'Malware Attack'\n",
      " 'Business Email CompromiseEmail Takeover' 'Email Hacking'\n",
      " 'Hacking/Defacement' 'Unauthorised AccessData Breach' 'SQL Injection'\n",
      " 'Provocative Speech for unlawful acts' 'Ransomware Attack'\n",
      " 'Cyber Terrorism' 'Tampering with computer source documents'\n",
      " 'DematDepository Fraud' 'Online Trafficking' 'Online Matrimonial Fraud'\n",
      " 'Website DefacementHacking' 'Damage to computer computer systems etc'\n",
      " 'Impersonating Email' 'EMail Phishing' 'Ransomware' 'Intimidating Email']\n"
     ]
    }
   ],
   "source": [
    "# Merge rare categories into a broader category\n",
    "train_df['category'] = train_df['category'].replace({\n",
    "    'Report Unlawful Content': 'Any Other Cyber Crime'  # Replace with a broader category\n",
    "})\n",
    "\n",
    "# Merge rare subcategories into a broader subcategory\n",
    "train_df['sub_category'] = train_df['sub_category'].replace({\n",
    "    'Against Interest of sovereignty or integrity of India': 'Unknown'  # Replace with a broader subcategory\n",
    "})\n",
    "\n",
    "# Verify the changes\n",
    "print(\"Updated Category Values:\", train_df['category'].unique())\n",
    "print(\"Updated Subcategory Values:\", train_df['sub_category'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1202d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Categories Sample: [9 7 8 9 7]\n",
      "Encoded Subcategories Sample: [ 3 14 20 21 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['subcategory_encoder.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoders\n",
    "category_encoder = LabelEncoder()\n",
    "subcategory_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the 'category' and 'sub_category' columns\n",
    "y_category = category_encoder.fit_transform(train_df['category'])\n",
    "y_subcategory = subcategory_encoder.fit_transform(train_df['sub_category'])\n",
    "\n",
    "# Display the encoded categories and subcategories\n",
    "print(\"Encoded Categories Sample:\", y_category[:5])\n",
    "print(\"Encoded Subcategories Sample:\", y_subcategory[:5])\n",
    "\n",
    "# Save the encoders for decoding predictions later\n",
    "import joblib\n",
    "joblib.dump(category_encoder, 'category_encoder.pkl')\n",
    "joblib.dump(subcategory_encoder, 'subcategory_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03858383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: (74932, 5000)\n",
      "Validation Set Shape: (18733, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data for category classification\n",
    "X_train, X_val, y_category_train, y_category_val = train_test_split(\n",
    "    X, y_category, test_size=0.2, random_state=42, stratify=y_category\n",
    ")\n",
    "\n",
    "# Split the data for subcategory classification\n",
    "_, _, y_subcategory_train, y_subcategory_val = train_test_split(\n",
    "    X, y_subcategory, test_size=0.2, random_state=42, stratify=y_subcategory\n",
    ")\n",
    "\n",
    "# Check the shape of the splits\n",
    "print(\"Training Set Shape:\", X_train.shape)\n",
    "print(\"Validation Set Shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57b90a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.26      0.33      2176\n",
      "           1       0.73      0.14      0.24        76\n",
      "           2       0.74      0.36      0.49        96\n",
      "           3       1.00      1.00      1.00       722\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.49      0.23      0.31       342\n",
      "           6       0.00      0.00      0.00        36\n",
      "           7       0.81      0.94      0.87     11483\n",
      "           8       0.33      0.01      0.02        89\n",
      "           9       0.56      0.59      0.57      2428\n",
      "          10       0.00      0.00      0.00        11\n",
      "          11       1.00      0.92      0.96       564\n",
      "          12       0.17      0.01      0.02       310\n",
      "          13       0.33      0.09      0.14       368\n",
      "\n",
      "    accuracy                           0.76     18733\n",
      "   macro avg       0.47      0.33      0.35     18733\n",
      "weighted avg       0.72      0.76      0.73     18733\n",
      "\n",
      "Category Classification Accuracy: 0.7595686755992099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ML\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ML\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ML\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "category_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "category_model.fit(X_train, y_category_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_category_pred = category_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Category Classification Report:\")\n",
    "print(classification_report(y_category_val, y_category_pred))\n",
    "print(\"Category Classification Accuracy:\", accuracy_score(y_category_val, y_category_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff8d9b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subcategory Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        58\n",
      "           1       0.00      0.00      0.00       398\n",
      "           2       0.00      0.00      0.00        96\n",
      "           3       0.00      0.00      0.00       818\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.00      0.00      0.00        22\n",
      "           6       0.00      0.00      0.00        97\n",
      "           7       0.11      0.02      0.03      2160\n",
      "           8       0.00      0.00      0.00       152\n",
      "           9       0.00      0.00      0.00       101\n",
      "          10       0.00      0.00      0.00        31\n",
      "          11       0.00      0.00      0.00       809\n",
      "          12       0.00      0.00      0.00        70\n",
      "          13       0.00      0.00      0.00       460\n",
      "          14       0.00      0.00      0.00      1161\n",
      "          15       0.00      0.00      0.00       108\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       0.12      0.01      0.02      1774\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00       104\n",
      "          20       0.00      0.00      0.00        89\n",
      "          21       0.00      0.00      0.00       182\n",
      "          22       0.00      0.00      0.00        26\n",
      "          23       0.00      0.00      0.00        37\n",
      "          24       0.12      0.02      0.04      2175\n",
      "          25       0.00      0.00      0.00       414\n",
      "          26       0.00      0.00      0.00        83\n",
      "          27       0.00      0.00      0.00        11\n",
      "          28       0.00      0.00      0.00       107\n",
      "          29       0.00      0.00      0.00       102\n",
      "          30       0.00      0.00      0.00       113\n",
      "          31       0.29      0.94      0.44      5369\n",
      "          32       0.00      0.00      0.00       223\n",
      "          33       0.11      0.00      0.01      1318\n",
      "          34       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.28     18733\n",
      "   macro avg       0.02      0.03      0.02     18733\n",
      "weighted avg       0.13      0.28      0.14     18733\n",
      "\n",
      "Subcategory Classification Accuracy: 0.27673090268510114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ML\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ML\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ML\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model for subcategory classification\n",
    "subcategory_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "subcategory_model.fit(X_train, y_subcategory_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_subcategory_pred = subcategory_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Subcategory Classification Report:\")\n",
    "print(classification_report(y_subcategory_val, y_subcategory_pred))\n",
    "print(\"Subcategory Classification Accuracy:\", accuracy_score(y_subcategory_val, y_subcategory_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2890320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subcategory Classification Report (with SMOTE):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        58\n",
      "           1       0.02      0.03      0.02       398\n",
      "           2       0.01      0.04      0.01        96\n",
      "           3       0.03      0.01      0.02       818\n",
      "           4       0.00      0.03      0.00        32\n",
      "           5       0.00      0.00      0.00        22\n",
      "           6       0.00      0.02      0.01        97\n",
      "           7       0.10      0.02      0.04      2160\n",
      "           8       0.01      0.03      0.01       152\n",
      "           9       0.00      0.00      0.00       101\n",
      "          10       0.00      0.00      0.00        31\n",
      "          11       0.04      0.02      0.03       809\n",
      "          12       0.00      0.01      0.00        70\n",
      "          13       0.03      0.02      0.02       460\n",
      "          14       0.05      0.02      0.02      1161\n",
      "          15       0.00      0.03      0.01       108\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       0.10      0.02      0.04      1774\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.02      0.01       104\n",
      "          20       0.00      0.02      0.01        89\n",
      "          21       0.01      0.02      0.01       182\n",
      "          22       0.00      0.00      0.00        26\n",
      "          23       0.00      0.03      0.00        37\n",
      "          24       0.10      0.02      0.04      2175\n",
      "          25       0.02      0.02      0.02       414\n",
      "          26       0.00      0.02      0.01        83\n",
      "          27       0.00      0.00      0.00        11\n",
      "          28       0.01      0.07      0.02       107\n",
      "          29       0.00      0.02      0.01       102\n",
      "          30       0.01      0.05      0.02       113\n",
      "          31       0.28      0.13      0.18      5369\n",
      "          32       0.01      0.03      0.02       223\n",
      "          33       0.10      0.03      0.04      1318\n",
      "          34       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.05     18733\n",
      "   macro avg       0.03      0.02      0.02     18733\n",
      "weighted avg       0.13      0.05      0.07     18733\n",
      "\n",
      "Subcategory Classification Accuracy (with SMOTE): 0.05359525970212993\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to oversample the minority classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_subcategory_train_smote = smote.fit_resample(X_train, y_subcategory_train)\n",
    "\n",
    "# Train the model on the balanced dataset\n",
    "subcategory_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "subcategory_model.fit(X_train_smote, y_subcategory_train_smote)\n",
    "\n",
    "# Evaluate the model\n",
    "y_subcategory_pred = subcategory_model.predict(X_val)\n",
    "\n",
    "print(\"Subcategory Classification Report (with SMOTE):\")\n",
    "print(classification_report(y_subcategory_val, y_subcategory_pred))\n",
    "print(\"Subcategory Classification Accuracy (with SMOTE):\", accuracy_score(y_subcategory_val, y_subcategory_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
